<h1 align="center"> Deep Neural Networks </h1>

<h4 align="center"> Reimplementation of a Deep Neural Network </h4>

<p align="center">
  <img src="https://img.shields.io/badge/Python-v3.6+-blue.svg">
  <img src="https://img.shields.io/badge/Pytorch-v1.3-orange.svg">
  <img src="https://img.shields.io/badge/Status-Complete-green.svg">
  <img src="https://img.shields.io/badge/License-MIT-blue.svg">
</p>

<p align="center">
  <a href="#About">About</a> •
  <a href="#Requirements">Requirements</a> •
  <a href="#Algorithm">Algorithm</a> •
  <a href="#Data">Data</a> •
  <a href="#Training">Training</a> •
  <a href="#Results">Results</a> •
  <a href="#Sources">Sources</a>
</p>

## About:
This is an implementation of a deep neural network with back propagation from scratch with pytorch (No Autograd)

## Requirements:
- Pytorch
- Matplotlib

## Algorithm:
This implementation uses a multilayer perceptron with standard backprobagation to make classication from the ___ dataset. Tanh was used in hidden layers and Sigmoid activations were used in the final layer.

## Data:
- explain the environment and/or data
- show screenshots/tables/plots

## Training:
- explain training methods
- plot accuracy and loss through training

## Results:
- show end result accuracy
- show prediction plot
- include closing thoughts + improvements

## Sources:
- show sources

## Meta:

Gregory Eales – [@GregoryHamE](https://twitter.com/GregoryHamE) – gregory.hamilton.e@gmail.com

Distributed under the MIT license. See ``LICENSE`` for more information.

[https://github.com/Gregory-Eales](https://github.com/Gregory-Eales)
